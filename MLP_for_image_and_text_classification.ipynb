{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A1 - MLP for image and text classification\n",
        "\n",
        "- Pytorch MLP image classification CIFAR10\n",
        "- Keras MLP image classification CIFAR10\n",
        "- Pytorch MLP text classification IMDB Movie reviews\n",
        "- Keras MLP text classification IMDB Movie reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq7G8xg_CKwg"
      },
      "source": [
        "## Pytorch MLP image classification CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GmNIxJWgqidB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYyyuXTDDwbw"
      },
      "source": [
        "### Import and Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lrzj6Ly7DvmE"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzSaWtpXBFk0",
        "outputId": "c9113b8a-0634-45e3-8ff1-37b0df37ba0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.0MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-SE-Xb57Fp7z"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx0ZlnIOGKzp",
        "outputId": "67281fc5-8827-4e44-96cc-c2f46366b799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra-xARMTGeYK"
      },
      "source": [
        "#### Class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g2VQR0izGRoK"
      },
      "outputs": [],
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVvoh2AKHR_O"
      },
      "source": [
        "### Defining the model architecture Using Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXTEqexMIwLH"
      },
      "source": [
        "Use of cuda to put our data and model on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "a9y1ovMZHQ7_"
      },
      "outputs": [],
      "source": [
        "device=torch.device('cuda:0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03tJ_uUgJ0W4"
      },
      "source": [
        "MLP Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vNPaA8vjJuCE"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP,self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(32 * 32 * 3,64)\n",
        "        self.fc2 = torch.nn.Linear(64,64)\n",
        "        self.fc3 = torch.nn.Linear(64,64)\n",
        "        self.fc4 = torch.nn.Linear(64,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = x.view(-1,32 * 32 * 3)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.softmax(self.fc4(x), dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6QwRHEILYkI",
        "outputId": "66bc04e9-efa5-4a35-9081-a67632fcdb0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                   [-1, 64]         196,672\n",
            "            Linear-2                   [-1, 64]           4,160\n",
            "            Linear-3                   [-1, 64]           4,160\n",
            "            Linear-4                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 205,642\n",
            "Trainable params: 205,642\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.78\n",
            "Estimated Total Size (MB): 0.80\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "mlp = MLP().to(device)\n",
        "summary(mlp,(3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzEQjAuYM2Wj"
      },
      "source": [
        "### Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6URoSGKNR8j"
      },
      "source": [
        "Before training:\n",
        "- Loss function: to measure how good the network is. We choose Cross entropy loss\n",
        "\n",
        "- Optimizer: to update network as it sees more data and reduce loss value. We use SGD optimizer.\n",
        "\n",
        "- Metrics: to monitor performance of network. We evaluate the model by using accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MCLJjZqYMNir"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FqBTDwrOB7b"
      },
      "source": [
        "Functions of train and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NnE162IsN7ZJ"
      },
      "outputs": [],
      "source": [
        "def train_cuda(running_loss,net,optimizer,epoch):\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 20 == 19:\n",
        "            print(\"Epoch:{}, Iteration:{}, Loss:{:.3f}\".format(epoch + 1, i + 1, running_loss / (i+1)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eagzzoTBQMar"
      },
      "outputs": [],
      "source": [
        "def test_cuda(net):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIY7WfcPQnSp"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1qRt_k32QgsZ",
        "outputId": "4eff1f63-28f1-4acb-a377-d8424b9db0b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:1, Iteration:20, Loss:2.302\n",
            "Epoch:1, Iteration:40, Loss:2.302\n",
            "Epoch:1, Iteration:60, Loss:2.301\n",
            "Epoch:1, Iteration:80, Loss:2.300\n",
            "Epoch:1, Iteration:100, Loss:2.298\n",
            "Epoch:1, Iteration:120, Loss:2.293\n",
            "Epoch:1, Iteration:140, Loss:2.289\n",
            "Epoch:1, Iteration:160, Loss:2.283\n",
            "Epoch:1, Iteration:180, Loss:2.277\n",
            "Epoch:1, Iteration:200, Loss:2.271\n",
            "Epoch:1, Iteration:220, Loss:2.266\n",
            "Epoch:1, Iteration:240, Loss:2.262\n",
            "Epoch:1, Iteration:260, Loss:2.257\n",
            "Epoch:1, Iteration:280, Loss:2.252\n",
            "Epoch:1, Iteration:300, Loss:2.247\n",
            "Epoch:1, Iteration:320, Loss:2.243\n",
            "Epoch:1, Iteration:340, Loss:2.239\n",
            "Epoch:1, Iteration:360, Loss:2.235\n",
            "Epoch:1, Iteration:380, Loss:2.231\n",
            "Accuracy of the network on the test images: 31 %\n",
            "Epoch:2, Iteration:20, Loss:2.133\n",
            "Epoch:2, Iteration:40, Loss:2.132\n",
            "Epoch:2, Iteration:60, Loss:2.127\n",
            "Epoch:2, Iteration:80, Loss:2.124\n",
            "Epoch:2, Iteration:100, Loss:2.121\n",
            "Epoch:2, Iteration:120, Loss:2.118\n",
            "Epoch:2, Iteration:140, Loss:2.118\n",
            "Epoch:2, Iteration:160, Loss:2.116\n",
            "Epoch:2, Iteration:180, Loss:2.113\n",
            "Epoch:2, Iteration:200, Loss:2.109\n",
            "Epoch:2, Iteration:220, Loss:2.107\n",
            "Epoch:2, Iteration:240, Loss:2.105\n",
            "Epoch:2, Iteration:260, Loss:2.104\n",
            "Epoch:2, Iteration:280, Loss:2.103\n",
            "Epoch:2, Iteration:300, Loss:2.102\n",
            "Epoch:2, Iteration:320, Loss:2.100\n",
            "Epoch:2, Iteration:340, Loss:2.099\n",
            "Epoch:2, Iteration:360, Loss:2.098\n",
            "Epoch:2, Iteration:380, Loss:2.097\n",
            "Accuracy of the network on the test images: 38 %\n",
            "Epoch:3, Iteration:20, Loss:2.067\n",
            "Epoch:3, Iteration:40, Loss:2.068\n",
            "Epoch:3, Iteration:60, Loss:2.066\n",
            "Epoch:3, Iteration:80, Loss:2.066\n",
            "Epoch:3, Iteration:100, Loss:2.065\n",
            "Epoch:3, Iteration:120, Loss:2.065\n",
            "Epoch:3, Iteration:140, Loss:2.066\n",
            "Epoch:3, Iteration:160, Loss:2.067\n",
            "Epoch:3, Iteration:180, Loss:2.065\n",
            "Epoch:3, Iteration:200, Loss:2.062\n",
            "Epoch:3, Iteration:220, Loss:2.062\n",
            "Epoch:3, Iteration:240, Loss:2.062\n",
            "Epoch:3, Iteration:260, Loss:2.061\n",
            "Epoch:3, Iteration:280, Loss:2.062\n",
            "Epoch:3, Iteration:300, Loss:2.062\n",
            "Epoch:3, Iteration:320, Loss:2.061\n",
            "Epoch:3, Iteration:340, Loss:2.061\n",
            "Epoch:3, Iteration:360, Loss:2.060\n",
            "Epoch:3, Iteration:380, Loss:2.060\n",
            "Accuracy of the network on the test images: 40 %\n",
            "Epoch:4, Iteration:20, Loss:2.040\n",
            "Epoch:4, Iteration:40, Loss:2.040\n",
            "Epoch:4, Iteration:60, Loss:2.037\n",
            "Epoch:4, Iteration:80, Loss:2.040\n",
            "Epoch:4, Iteration:100, Loss:2.040\n",
            "Epoch:4, Iteration:120, Loss:2.041\n",
            "Epoch:4, Iteration:140, Loss:2.041\n",
            "Epoch:4, Iteration:160, Loss:2.041\n",
            "Epoch:4, Iteration:180, Loss:2.038\n",
            "Epoch:4, Iteration:200, Loss:2.036\n",
            "Epoch:4, Iteration:220, Loss:2.037\n",
            "Epoch:4, Iteration:240, Loss:2.037\n",
            "Epoch:4, Iteration:260, Loss:2.037\n",
            "Epoch:4, Iteration:280, Loss:2.038\n",
            "Epoch:4, Iteration:300, Loss:2.038\n",
            "Epoch:4, Iteration:320, Loss:2.037\n",
            "Epoch:4, Iteration:340, Loss:2.037\n",
            "Epoch:4, Iteration:360, Loss:2.037\n",
            "Epoch:4, Iteration:380, Loss:2.037\n",
            "Accuracy of the network on the test images: 41 %\n",
            "Epoch:5, Iteration:20, Loss:2.035\n",
            "Epoch:5, Iteration:40, Loss:2.036\n",
            "Epoch:5, Iteration:60, Loss:2.027\n",
            "Epoch:5, Iteration:80, Loss:2.029\n",
            "Epoch:5, Iteration:100, Loss:2.028\n",
            "Epoch:5, Iteration:120, Loss:2.028\n",
            "Epoch:5, Iteration:140, Loss:2.031\n",
            "Epoch:5, Iteration:160, Loss:2.030\n",
            "Epoch:5, Iteration:180, Loss:2.027\n",
            "Epoch:5, Iteration:200, Loss:2.025\n",
            "Epoch:5, Iteration:220, Loss:2.024\n",
            "Epoch:5, Iteration:240, Loss:2.025\n",
            "Epoch:5, Iteration:260, Loss:2.024\n",
            "Epoch:5, Iteration:280, Loss:2.024\n",
            "Epoch:5, Iteration:300, Loss:2.025\n",
            "Epoch:5, Iteration:320, Loss:2.025\n",
            "Epoch:5, Iteration:340, Loss:2.025\n",
            "Epoch:5, Iteration:360, Loss:2.024\n",
            "Epoch:5, Iteration:380, Loss:2.024\n",
            "Accuracy of the network on the test images: 41 %\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "optimizer_mlp = optim.SGD(mlp.parameters(), lr=0.05, momentum=0.9)\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    train_cuda(running_loss,mlp,optimizer_mlp,epoch)\n",
        "    test_cuda(mlp)\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9VJSzJtSEND"
      },
      "source": [
        "## Keras MLP image classification CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-UjVN9y3SJb4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import cifar10\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP0Xd2F_SS6o",
        "outputId": "62a74db6-8e95-4279-dc5a-2f8c3a055ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6TWh-a7UkOQ",
        "outputId": "46264678-a4da-4aa7-b811-0ebd1898d85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of training data:\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "Shape of test data:\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of training data:\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"Shape of test data:\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dF9-fw3GVT1y"
      },
      "outputs": [],
      "source": [
        "# Transform label indices to one-hot encoded vectors\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
        "\n",
        "X_train = np.reshape(X_train,(50000,3072))\n",
        "X_test = np.reshape(X_test,(10000,3072))\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalization of pixel values (to [0-1] range)\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k_20ng9WBQu",
        "outputId": "aff8565c-3a6f-4d51-e1fe-c55b8e986fea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=3072))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "sgd = SGD(learning_rate =0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HH-m49n4YfNk"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_maAggS1WYOp",
        "outputId": "ba9acd65-19d1-48ad-eeee-c4917f4710a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2923 - loss: 1.9366 - val_accuracy: 0.3840 - val_loss: 1.7249\n",
            "Epoch 2/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4010 - loss: 1.6748 - val_accuracy: 0.3986 - val_loss: 1.6977\n",
            "Epoch 3/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4261 - loss: 1.5939 - val_accuracy: 0.4071 - val_loss: 1.6544\n",
            "Epoch 4/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4524 - loss: 1.5355 - val_accuracy: 0.4474 - val_loss: 1.5778\n",
            "Epoch 5/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4558 - loss: 1.5151 - val_accuracy: 0.4505 - val_loss: 1.5364\n",
            "Epoch 6/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4712 - loss: 1.4758 - val_accuracy: 0.4578 - val_loss: 1.5356\n",
            "Epoch 7/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4743 - loss: 1.4577 - val_accuracy: 0.4601 - val_loss: 1.5300\n",
            "Epoch 8/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4914 - loss: 1.4168 - val_accuracy: 0.4373 - val_loss: 1.5865\n",
            "Epoch 9/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4905 - loss: 1.4195 - val_accuracy: 0.4699 - val_loss: 1.5106\n",
            "Epoch 10/10\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5040 - loss: 1.3958 - val_accuracy: 0.4639 - val_loss: 1.5398\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,y_train, epochs=10, batch_size=32, verbose=1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhAMalKEZNvc"
      },
      "source": [
        "Evaluating the MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cvTV5MmsYkfb"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN-MDp3JZDi5",
        "outputId": "8f1023e9-8575-403e-a7fc-82b869fcb0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss', 'compile_metrics']\n",
            "[1.5108673572540283, 0.46369999647140503]\n"
          ]
        }
      ],
      "source": [
        "print(model.metrics_names)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojDND74SZ3kH"
      },
      "source": [
        "## Pytorch MLP text classification IMDB Movie reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoOhLkxUtjs0",
        "outputId": "f587f841-c244-4aca-c657-4b65f23ecf52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.5.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (11.8.86)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.3.0->torchtext) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (3.0.2)\n",
            "Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torchtext\n",
            "Successfully installed torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "s8af4of2mhil",
        "outputId": "c30d573a-c27d-4db8-d6de-13f468a7f9e4"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cafdb78469f3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "olbyVkBbpHXH",
        "outputId": "0e7273ff-1f4a-4b92-f649-9a68f40cc6fa"
      },
      "outputs": [],
      "source": [
        "# Charger le dataset IMDB\n",
        "dataset = load_dataset(\"imdb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8YYu1R5fJ5M"
      },
      "source": [
        "## Keras MLP text classification IMDB Movie reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "F6Ef34o-fTYu"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsMfBBJ9fpPy",
        "outputId": "e6a6be20-23eb-4866-a736-485866bb14e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7K-yezif-Ll",
        "outputId": "9b3eefc2-e9c4-4451-b0aa-963d38573870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ]
        }
      ],
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZreKvUJFgLqh",
        "outputId": "8d0ed30a-b880-4b6a-b566-ae76df42a00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ],
      "source": [
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLhdiuifhJAF"
      },
      "source": [
        "Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RIANKSMhKlH",
        "outputId": "c9088f53-baf2-46b0-8094-3522f78557ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "word_index = imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRy4b7KXickC"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "InHLFtxCiMJp",
        "outputId": "bb3a335c-a7ee-40d4-8e8e-43af59cd2ba0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WF5Feev8jHUh"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJDIsdgQjXGs"
      },
      "source": [
        "Create a validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "h449Z-BJjJt2"
      },
      "outputs": [],
      "source": [
        "x_val = train_data[:10000]\n",
        "x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "y_train = train_labels[10000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0gc_Wfhj5RJ"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z1kn-ixHj621",
        "outputId": "e329dd03-f4e9-432a-be76-60460b1b09ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 269ms/step - acc: 0.5039 - loss: 0.6931 - val_acc: 0.5159 - val_loss: 0.6930\n",
            "Epoch 2/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - acc: 0.5046 - loss: 0.6931 - val_acc: 0.5080 - val_loss: 0.6930\n",
            "Epoch 3/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 205ms/step - acc: 0.5004 - loss: 0.6930 - val_acc: 0.4999 - val_loss: 0.6930\n",
            "Epoch 4/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 205ms/step - acc: 0.4925 - loss: 0.6931 - val_acc: 0.5006 - val_loss: 0.6930\n",
            "Epoch 5/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - acc: 0.4944 - loss: 0.6931 - val_acc: 0.4995 - val_loss: 0.6930\n",
            "Epoch 6/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - acc: 0.5067 - loss: 0.6930 - val_acc: 0.4989 - val_loss: 0.6930\n",
            "Epoch 7/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - acc: 0.5029 - loss: 0.6930 - val_acc: 0.5004 - val_loss: 0.6930\n",
            "Epoch 8/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - acc: 0.5043 - loss: 0.6929 - val_acc: 0.5034 - val_loss: 0.6930\n",
            "Epoch 9/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - acc: 0.5050 - loss: 0.6929 - val_acc: 0.5072 - val_loss: 0.6930\n",
            "Epoch 10/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 203ms/step - acc: 0.5088 - loss: 0.6930 - val_acc: 0.5086 - val_loss: 0.6930\n",
            "Epoch 11/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 202ms/step - acc: 0.5082 - loss: 0.6930 - val_acc: 0.5088 - val_loss: 0.6930\n",
            "Epoch 12/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - acc: 0.5217 - loss: 0.6929 - val_acc: 0.5096 - val_loss: 0.6930\n",
            "Epoch 13/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - acc: 0.5172 - loss: 0.6929 - val_acc: 0.5098 - val_loss: 0.6930\n",
            "Epoch 14/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - acc: 0.5180 - loss: 0.6929 - val_acc: 0.5071 - val_loss: 0.6930\n",
            "Epoch 15/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 200ms/step - acc: 0.5174 - loss: 0.6929 - val_acc: 0.5075 - val_loss: 0.6930\n",
            "Epoch 16/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 209ms/step - acc: 0.5157 - loss: 0.6930 - val_acc: 0.5075 - val_loss: 0.6930\n",
            "Epoch 17/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - acc: 0.5178 - loss: 0.6929 - val_acc: 0.5084 - val_loss: 0.6930\n",
            "Epoch 18/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - acc: 0.5163 - loss: 0.6929 - val_acc: 0.5077 - val_loss: 0.6930\n",
            "Epoch 19/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - acc: 0.5137 - loss: 0.6929 - val_acc: 0.5082 - val_loss: 0.6930\n",
            "Epoch 20/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 196ms/step - acc: 0.5132 - loss: 0.6929 - val_acc: 0.5076 - val_loss: 0.6930\n",
            "Epoch 21/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - acc: 0.5126 - loss: 0.6930 - val_acc: 0.5079 - val_loss: 0.6930\n",
            "Epoch 22/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - acc: 0.5164 - loss: 0.6930 - val_acc: 0.5072 - val_loss: 0.6930\n",
            "Epoch 23/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - acc: 0.5174 - loss: 0.6929 - val_acc: 0.5072 - val_loss: 0.6930\n",
            "Epoch 24/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - acc: 0.5213 - loss: 0.6928 - val_acc: 0.5073 - val_loss: 0.6930\n",
            "Epoch 25/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 196ms/step - acc: 0.5154 - loss: 0.6929 - val_acc: 0.5061 - val_loss: 0.6930\n",
            "Epoch 26/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - acc: 0.5167 - loss: 0.6929 - val_acc: 0.5062 - val_loss: 0.6930\n",
            "Epoch 27/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - acc: 0.5186 - loss: 0.6928 - val_acc: 0.5061 - val_loss: 0.6930\n",
            "Epoch 28/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - acc: 0.5183 - loss: 0.6929 - val_acc: 0.5058 - val_loss: 0.6930\n",
            "Epoch 29/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - acc: 0.5182 - loss: 0.6929 - val_acc: 0.5073 - val_loss: 0.6930\n",
            "Epoch 30/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 196ms/step - acc: 0.5192 - loss: 0.6929 - val_acc: 0.5072 - val_loss: 0.6930\n",
            "Epoch 31/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 198ms/step - acc: 0.5173 - loss: 0.6928 - val_acc: 0.5071 - val_loss: 0.6930\n",
            "Epoch 32/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - acc: 0.5178 - loss: 0.6928 - val_acc: 0.5057 - val_loss: 0.6930\n",
            "Epoch 33/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - acc: 0.5092 - loss: 0.6930 - val_acc: 0.5063 - val_loss: 0.6930\n",
            "Epoch 34/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - acc: 0.5131 - loss: 0.6929 - val_acc: 0.5063 - val_loss: 0.6930\n",
            "Epoch 35/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - acc: 0.5212 - loss: 0.6928 - val_acc: 0.5065 - val_loss: 0.6930\n",
            "Epoch 36/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - acc: 0.5183 - loss: 0.6929 - val_acc: 0.5065 - val_loss: 0.6930\n",
            "Epoch 37/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 197ms/step - acc: 0.5110 - loss: 0.6930 - val_acc: 0.5063 - val_loss: 0.6930\n",
            "Epoch 38/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 196ms/step - acc: 0.5187 - loss: 0.6928 - val_acc: 0.5076 - val_loss: 0.6930\n",
            "Epoch 39/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - acc: 0.5187 - loss: 0.6928 - val_acc: 0.5064 - val_loss: 0.6930\n",
            "Epoch 40/40\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - acc: 0.5098 - loss: 0.6929 - val_acc: 0.5084 - val_loss: 0.6930\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icdxuESKkSwp"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPQm0c_ukSa7",
        "outputId": "859424ff-aec2-456b-92c0-a51f141a5919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.5157 - loss: 0.6928\n",
            "[0.6929470896720886, 0.5096799731254578]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
